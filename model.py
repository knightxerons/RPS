# -*- coding: utf-8 -*-
"""Rock Paper Scisors (Reinforcement learning).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vpouLcBSJAY9fypbL7WBSWVeRDJJatPW

**Importing the libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf 
import keras

#Utils Functions
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2

"""**Defining the directories path**"""

train_dir='/content/drive/My Drive/ML Datasets/RPS_Dataset/train'
val_dir='/content/drive/My Drive/ML Datasets/RPS_Dataset/validation'

"""**HyperParameters**"""

num_classes = 3 
img_rows = 128
img_cols = 128
bs = 32
ep=50

"""**Data augmentation**"""

#Train Augmentation Params
train_datagen = ImageDataGenerator(
    rescale=1./225,
    rotation_range=30,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

#Validation Augmentation Params
val_datagen = ImageDataGenerator(
    rescale=1./225
)

#Train Data Generator
train_generator = train_datagen.flow_from_directory(
    train_dir,
    color_mode='grayscale',
    target_size=(img_rows,img_cols),
    batch_size=bs,
    class_mode='categorical',
    shuffle=True
)

#Validation Data Generator
val_generator = val_datagen.flow_from_directory(
    val_dir,
    color_mode='grayscale',
    target_size=(img_rows,img_cols),
    batch_size=bs,
    class_mode='categorical',
    shuffle=True
)

"""**Building The Model**"""

cnn=keras.Sequential()

# Step 1 - Convolution
cnn.add(keras.layers.Conv2D(filters=16, kernel_size=3,kernel_initializer='he_normal', padding="same", activation="elu", input_shape=[128,128, 1],bias_regularizer=l2(0.001)))
# Step 2 - Pooling
cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Step 1 - Convolution
cnn.add(keras.layers.Conv2D(filters=32, kernel_size=3,kernel_initializer='he_normal', padding="same", activation="elu",bias_regularizer=l2(0.001)))
# Step 2 - Pooling
cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Step 1 - Convolution
cnn.add(keras.layers.Conv2D(filters=64, kernel_size=3,kernel_initializer='he_normal', padding="same", activation="elu",bias_regularizer=l2(0.001)))
# Step 2 - Pooling
cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Step 1 - Convolution
cnn.add(keras.layers.Conv2D(filters=128, kernel_size=3,kernel_initializer='he_normal', padding="same", activation="elu",bias_regularizer=l2(0.001)))
# Step 2 - Pooling
cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Step 3 - Flattening
cnn.add(keras.layers.Flatten())
# Step 4 - Full Connection
cnn.add(keras.layers.Dense(units=256, activation='elu'))
# Step 5 - Output Layer
cnn.add(keras.layers.Dense(units=3, activation='softmax'))

#Model_summary
print(cnn.summary(),'\n')

"""**Early Stopping**"""

from keras.optimizers import RMSprop,SGD,Adam
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

checkpoint = ModelCheckpoint('Prediction1.h5',
                             monitor='val_loss',
                             mode='min',
                             save_best_only=True,
                             verbose=1)

earlystop = EarlyStopping(monitor='val_loss',
                          min_delta=0,
                          patience=5,
                          verbose=1,
                          restore_best_weights=True
                          )

reduce_lr = ReduceLROnPlateau(monitor='val_loss',
                              factor=0.2,
                              patience=3,
                              verbose=1,
                              min_delta=0.0001)

callbacks = [earlystop,checkpoint,reduce_lr]

"""**Compilation**"""

cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=["accuracy"])

nb_train_samples = 3600
nb_validation_samples = 900

history=cnn.fit_generator(
                train_generator,
                steps_per_epoch=nb_train_samples//bs,
                epochs=ep,
                callbacks=callbacks,
                validation_data=val_generator,
                validation_steps=nb_validation_samples//bs)